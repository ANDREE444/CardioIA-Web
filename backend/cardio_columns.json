import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Load the dataset
df = pd.read_csv('/content/heart_disease_dataset.csv')

# --- Data Preprocessing ---

# Handle missing values in 'Alcohol Intake' by filling with the mode
df['Alcohol Intake'].fillna(df['Alcohol Intake'].mode()[0], inplace=True)

# Identify categorical features (based on previous analysis, excluding the target)
categorical_cols = ['Gender', 'Smoking', 'Alcohol Intake', 'Exercise Hours', 'Family History', 'Diabetes', 'Obesity', 'Stress Level', 'Exercise Induced Angina', 'Chest Pain Type']

# One-hot encode categorical features
df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# Separate features (X) and target (y)
X = df.drop('Heart Disease', axis=1)
y = df['Heart Disease']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Identify numerical columns
numerical_cols = ['Age', 'Cholesterol', 'Blood Pressure', 'Heart Rate', 'Blood Sugar']

# Scale numerical features
scaler = StandardScaler()
X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])
X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])

# --- Logistic Regression Model ---

# Instantiate the Logistic Regression model
model = LogisticRegression(random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test data
y_pred = model.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print("\nClassification Report:")
print(classification_rep)
print("\nConfusion Matrix:")
display(conf_matrix)
# ... (todo tu código de model.fit() y y_pred va aquí arriba)
import joblib
import json

# --- 1. Guardar el Modelo ---
# Guarda el modelo de Regresión Logística entrenado
joblib.dump(model, 'cardio_model.pkl')

# --- 2. Guardar el Scaler ---
# Guarda el scaler que fue "ajustado" (fit) solo con los datos de entrenamiento
joblib.dump(scaler, 'cardio_scaler.pkl')

# --- 3. Guardar las Columnas ---
# ¡ESTE ES EL PASO MÁS IMPORTANTE!
# Guardamos la lista exacta de nombres de columnas (después del One-Hot Encoding)
# con las que el modelo fue entrenado.
train_columns = X_train.columns.tolist()
with open('cardio_columns.json', 'w') as f:
    json.dump(train_columns, f)

print("\n--- ¡Archivos Guardados! ---")
print("Modelo guardado en: cardio_model.pkl")
print("Scaler guardado en: cardio_scaler.pkl")
print("Columnas guardadas en: cardio_columns.json")